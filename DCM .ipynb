{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ea1a50-9937-436b-84d9-b913e303472e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCM data saved for s01: 2 electrodes, shapes (540180, 2)/(540180, 2)\n"
     ]
    }
   ],
   "source": [
    "### Preprocessing \n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Set up data directories\n",
    "data_dir = './data_ephys/'\n",
    "behav_dir = './data_behav/'\n",
    "\n",
    "# Find available subjects\n",
    "subjects = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.mat') and file.startswith('s'):\n",
    "        subject_id = file.split('_')[0]\n",
    "        subjects.append(subject_id)\n",
    "\n",
    "# Select target subject\n",
    "target_subject = 's01'\n",
    "\n",
    "# Load electrophysiology data\n",
    "ephys_file = f'{data_dir}{target_subject}_ofc_hg_events.mat'\n",
    "data = sio.loadmat(ephys_file)\n",
    "\n",
    "# Load main data matrices\n",
    "game_data = data['game_events_hg']  # nTrials × nTimePoints × nElectrodes\n",
    "button_data = data['buttonpress_events_hg']  # nTrials × nTimePoints × nElectrodes\n",
    "\n",
    "# Load behavioral data\n",
    "csv_file = f'{behav_dir}gamble.data.{target_subject}.csv'\n",
    "trial_data = pd.read_csv(csv_file)\n",
    "\n",
    "def find_task_responsive_electrodes(data_matrix, percentile_threshold=75):\n",
    "    \"\"\"Find electrodes that show strong task-related activity\"\"\"\n",
    "    n_electrodes = data_matrix.shape[2]\n",
    "    electrode_responsiveness = []\n",
    "    \n",
    "    for e in range(n_electrodes):\n",
    "        electrode_data = data_matrix[:, :, e]\n",
    "        avg_response = np.mean(electrode_data, axis=0)\n",
    "        response_variance = np.var(avg_response)\n",
    "        \n",
    "        electrode_responsiveness.append({\n",
    "            'electrode': e,\n",
    "            'variance': response_variance,\n",
    "            'mean_activity': np.mean(electrode_data)\n",
    "        })\n",
    "    \n",
    "    # Sort by responsiveness and get top electrodes\n",
    "    electrode_responsiveness.sort(key=lambda x: x['variance'], reverse=True)\n",
    "    threshold = np.percentile([e['variance'] for e in electrode_responsiveness], percentile_threshold)\n",
    "    responsive_electrodes = [e for e in electrode_responsiveness if e['variance'] >= threshold]\n",
    "    \n",
    "    return responsive_electrodes\n",
    "\n",
    "def extract_electrode_timeseries(data_matrix, electrode_indices):\n",
    "    \"\"\"Extract time series for selected electrodes\"\"\"\n",
    "    selected_data = data_matrix[:, :, electrode_indices]\n",
    "    concatenated_data = selected_data.reshape(-1, len(electrode_indices))\n",
    "    \n",
    "    return concatenated_data\n",
    "\n",
    "def preprocess_timeseries(timeseries_data):\n",
    "    \"\"\"Basic preprocessing for DCM\"\"\"\n",
    "    # Remove DC component and normalize\n",
    "    timeseries_centered = timeseries_data - np.mean(timeseries_data, axis=0)\n",
    "    timeseries_normalized = (timeseries_centered - np.mean(timeseries_centered, axis=0)) / np.std(timeseries_centered, axis=0)\n",
    "    \n",
    "    return timeseries_normalized\n",
    "\n",
    "# Find responsive electrodes and select top N\n",
    "game_responsive = find_task_responsive_electrodes(game_data)\n",
    "button_responsive = find_task_responsive_electrodes(button_data)\n",
    "\n",
    "# Select top 4 most responsive electrodes\n",
    "n_electrodes = 4\n",
    "selected_electrodes = [e['electrode'] for e in game_responsive[:n_electrodes]]\n",
    "\n",
    "# Extract and preprocess time series\n",
    "game_timeseries = extract_electrode_timeseries(game_data, selected_electrodes)\n",
    "button_timeseries = extract_electrode_timeseries(button_data, selected_electrodes)\n",
    "\n",
    "game_processed = preprocess_timeseries(game_timeseries)\n",
    "button_processed = preprocess_timeseries(button_timeseries)\n",
    "\n",
    "# Create and save final data structure for DCM\n",
    "dcm_data = {\n",
    "    'subject_id': target_subject,\n",
    "    'selected_electrodes': selected_electrodes,\n",
    "    'game_locked': {'Y': game_processed, 'dt': 1/1000},\n",
    "    'button_locked': {'Y': button_processed, 'dt': 1/1000},\n",
    "    'behavioral_data': trial_data\n",
    "}\n",
    "\n",
    "with open(f'dcm_ready_data_{target_subject}.pkl', 'wb') as f:\n",
    "    pickle.dump(dcm_data, f)\n",
    "\n",
    "print(f\"DCM data saved for {target_subject}: {len(selected_electrodes)} electrodes, shapes {game_processed.shape}/{button_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3aec799-a423-4a56-a7d0-5a17da38883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCM inputs created: (540180, 3), 180.0 game onsets, ready for network design\n"
     ]
    }
   ],
   "source": [
    "### Step 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load processed data\n",
    "with open('dcm_ready_data_s01.pkl', 'rb') as f:\n",
    "    dcm_data = pickle.load(f)\n",
    "\n",
    "behavioral_data = dcm_data['behavioral_data']\n",
    "\n",
    "def create_input_timeseries(behavioral_data, neural_length, sampling_rate=1000):\n",
    "    \"\"\"Create DCM input matrix aligned with neural data\"\"\"\n",
    "    # Initialize input matrix: time × inputs\n",
    "    U = np.zeros((neural_length, 3))\n",
    "    \n",
    "    # Parameters\n",
    "    trial_length = 3001   # 3001 time points per trial\n",
    "    \n",
    "    # Get valid trials (exclude timeouts)\n",
    "    valid_trials = behavioral_data[behavioral_data['choice.class'] != 'Timeout'].copy()\n",
    "    valid_trials = valid_trials.reset_index(drop=True)\n",
    "    \n",
    "    # Create inputs for each trial\n",
    "    for trial_idx, trial in valid_trials.iterrows():\n",
    "        if trial_idx >= neural_length // trial_length:\n",
    "            break  # Don't exceed neural data length\n",
    "            \n",
    "        # Calculate trial start in neural data\n",
    "        trial_start = trial_idx * trial_length\n",
    "        trial_end = trial_start + trial_length\n",
    "        \n",
    "        if trial_end > neural_length:\n",
    "            break\n",
    "            \n",
    "        # INPUT 1: Game onset (driving input)\n",
    "        game_onset_sample = trial_start + 750  # Game presents at 750ms\n",
    "        if game_onset_sample < neural_length:\n",
    "            U[game_onset_sample, 0] = 1.0\n",
    "        \n",
    "        # INPUT 2: Choice type (modulatory - sustained)\n",
    "        choice_value = 1.0 if trial['choice.class'] == 'Gamble' else 0.0\n",
    "        choice_start = trial_start + 750\n",
    "        choice_duration = 2000  # Up to 2s choice period\n",
    "        choice_end = min(choice_start + choice_duration, trial_end)\n",
    "        U[choice_start:choice_end, 1] = choice_value\n",
    "        \n",
    "        # INPUT 3: Outcome (modulatory - transient)\n",
    "        outcome_value = 1.0 if 'Won' in str(trial['outcome']) else 0.0\n",
    "        outcome_sample = choice_start + 550  # Outcome at ~1.3s after choice\n",
    "        outcome_duration = 500  # 500ms outcome processing\n",
    "        outcome_end = min(outcome_sample + outcome_duration, trial_end)\n",
    "        \n",
    "        if outcome_sample < neural_length:\n",
    "            U[outcome_sample:outcome_end, 2] = outcome_value\n",
    "    \n",
    "    return U\n",
    "\n",
    "# Create the input matrix\n",
    "U = create_input_timeseries(behavioral_data, dcm_data['game_locked']['Y'].shape[0])\n",
    "\n",
    "# Create final DCM input structure\n",
    "dcm_inputs = {\n",
    "    'U': U,  # Input matrix (time × inputs)\n",
    "    'dt': 1/1000,  # Sampling interval\n",
    "    'input_names': ['GameOnset', 'ChoiceType', 'Outcome'],\n",
    "    'input_descriptions': {\n",
    "        'GameOnset': 'Driving input - game presentation onset',\n",
    "        'ChoiceType': 'Modulatory input - choice context (gamble vs safe)',\n",
    "        'Outcome': 'Modulatory input - outcome valence (win vs loss)'\n",
    "    },\n",
    "    'input_types': ['driving', 'modulatory', 'modulatory']\n",
    "}\n",
    "\n",
    "# Add to DCM data structure and save\n",
    "dcm_data['inputs'] = dcm_inputs\n",
    "\n",
    "with open('dcm_ready_data_s01.pkl', 'wb') as f:\n",
    "    pickle.dump(dcm_data, f)\n",
    "\n",
    "print(f\"DCM inputs created: {U.shape}, {np.sum(U[:,0])} game onsets, ready for network design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c1c952-2654-492c-b901-cd65ffdd0682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCM architecture complete: E3→E1=0.285, E1→E3=0.264, ready for model specification\n"
     ]
    }
   ],
   "source": [
    "### Step 3\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def estimate_connectivity_from_data(Y, method='correlation'):\n",
    "    \"\"\"Estimate initial connectivity strengths from neural data\"\"\"\n",
    "    \n",
    "    if method == 'correlation':\n",
    "        # Simple cross-correlation approach\n",
    "        corr_forward = np.corrcoef(Y[:-1, 0], Y[1:, 1])[0, 1]  # E3(t) → E1(t+1)\n",
    "        corr_backward = np.corrcoef(Y[:-1, 1], Y[1:, 0])[0, 1]  # E1(t) → E3(t+1)\n",
    "        \n",
    "        # Scale correlations to reasonable connection strengths\n",
    "        A_forward = np.clip(abs(corr_forward) * 1.5, 0.1, 0.9)\n",
    "        A_backward = np.clip(abs(corr_backward) * 1.2, 0.1, 0.7)\n",
    "        \n",
    "    elif method == 'adaptive':\n",
    "        # Adaptive based on signal characteristics\n",
    "        signal_var = np.var(Y, axis=0)\n",
    "        signal_ratio = signal_var[0] / signal_var[1]  # E3/E1 variance ratio\n",
    "        cross_corr = np.corrcoef(Y[:, 0], Y[:, 1])[0, 1]\n",
    "        \n",
    "        # Adaptive logic based on which electrode is more active\n",
    "        if signal_ratio > 1.2:  # E3 more variable → likely upstream\n",
    "            A_forward = min(0.9, abs(cross_corr) * 1.5)   # Strong E3→E1\n",
    "            A_backward = min(0.6, abs(cross_corr) * 1.0)  # Moderate E1→E3\n",
    "        else:  # More balanced\n",
    "            A_forward = min(0.7, abs(cross_corr) * 1.2)\n",
    "            A_backward = min(0.7, abs(cross_corr) * 1.2)\n",
    "    \n",
    "    return A_forward, A_backward\n",
    "\n",
    "def estimate_task_specific_connectivity(Y, U, trial_length=3001):\n",
    "    \"\"\"Estimate connectivity during choice phase (most relevant for decision-making)\"\"\"\n",
    "    \n",
    "    # Define choice phase (in samples)\n",
    "    choice_start, choice_end = 750, 2750\n",
    "    \n",
    "    n_trials = Y.shape[0] // trial_length\n",
    "    correlations_forward = []\n",
    "    correlations_backward = []\n",
    "    \n",
    "    for trial in range(min(n_trials, 20)):  # Use first 20 trials\n",
    "        trial_start = trial * trial_length\n",
    "        \n",
    "        # Extract choice phase data\n",
    "        y_phase = Y[trial_start + choice_start:trial_start + choice_end, :]\n",
    "        \n",
    "        if len(y_phase) > 10:  # Ensure enough data points\n",
    "            corr_f = np.corrcoef(y_phase[:-1, 0], y_phase[1:, 1])[0, 1]\n",
    "            corr_b = np.corrcoef(y_phase[:-1, 1], y_phase[1:, 0])[0, 1]\n",
    "            \n",
    "            if not np.isnan(corr_f): correlations_forward.append(corr_f)\n",
    "            if not np.isnan(corr_b): correlations_backward.append(corr_b)\n",
    "    \n",
    "    # Average across trials and scale to reasonable connection strengths\n",
    "    avg_forward = np.mean(correlations_forward) if correlations_forward else 0\n",
    "    avg_backward = np.mean(correlations_backward) if correlations_backward else 0\n",
    "    \n",
    "    A_forward = np.clip(abs(avg_forward) * 1.3, 0.2, 0.8)\n",
    "    A_backward = np.clip(abs(avg_backward) * 1.1, 0.2, 0.6)\n",
    "    \n",
    "    return A_forward, A_backward\n",
    "\n",
    "def create_dcm_matrices(Y, U):\n",
    "    \"\"\"Create A, B, and C matrices for 2-electrode DCM with data-driven connectivity\"\"\"\n",
    "    \n",
    "    # Estimate connectivity using multiple methods\n",
    "    A_forward_1, A_backward_1 = estimate_connectivity_from_data(Y, method='correlation')\n",
    "    A_forward_2, A_backward_2 = estimate_connectivity_from_data(Y, method='adaptive')\n",
    "    A_forward_3, A_backward_3 = estimate_task_specific_connectivity(Y, U)\n",
    "    \n",
    "    # Combine estimates (weighted average)\n",
    "    A_forward = (A_forward_1 * 0.3 + A_forward_2 * 0.4 + A_forward_3 * 0.3)\n",
    "    A_backward = (A_backward_1 * 0.3 + A_backward_2 * 0.4 + A_backward_3 * 0.3)\n",
    "    \n",
    "    # Create A matrix with data-driven values\n",
    "    A_prior = np.array([\n",
    "        [-1.0, A_backward],    \n",
    "        [A_forward, -1.0]      \n",
    "    ])\n",
    "    \n",
    "    # C matrix (driving inputs)\n",
    "    C_prior = np.array([\n",
    "        [1.0, 0.0, 0.0],  # Game onset drives E3 strongly\n",
    "        [0.5, 0.0, 0.0]   # Game onset drives E1 moderately\n",
    "    ])\n",
    "    \n",
    "    # B matrices (modulatory effects)\n",
    "    B_prior = np.zeros((3, 2, 2))\n",
    "    B_prior[1, 1, 0] = 0.3  # Choice type modulates E3→E1\n",
    "    B_prior[2, 0, 0] = 0.2  # Outcome modulates E3 self-connection\n",
    "    B_prior[2, 1, 1] = 0.2  # Outcome modulates E1 self-connection\n",
    "    \n",
    "    return A_prior, B_prior, C_prior, A_forward, A_backward\n",
    "\n",
    "# Load data and create DCM matrices\n",
    "with open('dcm_ready_data_s01.pkl', 'rb') as f:\n",
    "    dcm_data = pickle.load(f)\n",
    "\n",
    "Y = dcm_data['game_locked']['Y']\n",
    "U = dcm_data['inputs']['U']\n",
    "\n",
    "# Create matrices with data-driven connectivity\n",
    "A, B, C, forward_strength, backward_strength = create_dcm_matrices(Y, U)\n",
    "\n",
    "# Add architecture to DCM data\n",
    "dcm_data['architecture'] = {\n",
    "    'A': A,  # Intrinsic connections\n",
    "    'B': B,  # Modulatory connections  \n",
    "    'C': C,  # Driving connections\n",
    "    'connectivity_strengths': {\n",
    "        'E3_to_E1': forward_strength,\n",
    "        'E1_to_E3': backward_strength\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save complete DCM specification\n",
    "with open('dcm_ready_data_s01.pkl', 'wb') as f:\n",
    "    pickle.dump(dcm_data, f)\n",
    "\n",
    "print(f\"DCM architecture complete: E3→E1={forward_strength:.3f}, E1→E3={backward_strength:.3f}, ready for model specification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38aa0418-547a-418b-9894-63943acc27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCM specification complete: 540180 timepoints, 9 free parameters, ready for estimation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load DCM data\n",
    "with open('dcm_ready_data_s01.pkl', 'rb') as f:\n",
    "    dcm_data = pickle.load(f)\n",
    "\n",
    "def setup_dcm_priors():\n",
    "    \"\"\"Set up prior distributions for DCM parameters (ECoG-optimized)\"\"\"\n",
    "    return {\n",
    "        'A': {\n",
    "            'mean': np.array([[-0.5,  0.0], [ 0.0, -0.5]]),\n",
    "            'variance': 0.25 * np.ones((2, 2))\n",
    "        },\n",
    "        'B': {\n",
    "            'mean': np.zeros((3, 2, 2)),\n",
    "            'variance': 0.1 * np.ones((3, 2, 2))\n",
    "        },\n",
    "        'C': {\n",
    "            'mean': np.array([[0.5, 0.0, 0.0], [0.2, 0.0, 0.0]]),\n",
    "            'variance': 0.5 * np.ones((2, 3))\n",
    "        },\n",
    "        'temporal_scaling': {'mean': 2.0, 'variance': 0.5},  # Faster dynamics for ECoG\n",
    "        'noise': {'precision_prior': 1.0, 'precision_shape': 1.0}\n",
    "    }\n",
    "\n",
    "def setup_parameter_constraints():\n",
    "    \"\"\"Define which parameters are free vs fixed\"\"\"\n",
    "    return {\n",
    "        'A_free': np.array([[True,  True], [True,  True]]),\n",
    "        'B_free': np.array([\n",
    "            [[False, False], [False, False]],  # B1: No modulation by driving input\n",
    "            [[False, True],  [False, False]],  # B2: Choice modulates E3→E1 only  \n",
    "            [[True,  False], [False, True]]    # B3: Outcome modulates self-connections\n",
    "        ]),\n",
    "        'C_free': np.array([[True, False, False], [True, False, False]]),\n",
    "        'stability_constraint': True,\n",
    "        'connection_threshold': 0.05\n",
    "    }\n",
    "\n",
    "def dcm_forward_model(params, U, dt=0.001):\n",
    "    \"\"\"\n",
    "    Forward model: simulate neural responses given parameters and inputs\n",
    "    Core DCM equation: dz/dt = (A + Σ u_j B_j)z + Cu\n",
    "    \"\"\"\n",
    "    A, B, C = params['A'], params['B'], params['C']\n",
    "    n_time, n_inputs = U.shape\n",
    "    n_regions = A.shape[0]\n",
    "    \n",
    "    # Initialize state\n",
    "    z = np.zeros((n_time, n_regions))\n",
    "    \n",
    "    # Integrate over time using Euler method\n",
    "    for t in range(1, n_time):\n",
    "        z_curr = z[t-1, :]\n",
    "        u_curr = U[t-1, :]\n",
    "        \n",
    "        # Effective connectivity matrix: A + Σ u_j B_j\n",
    "        A_eff = A.copy()\n",
    "        for j in range(n_inputs):\n",
    "            A_eff += u_curr[j] * B[j]\n",
    "        \n",
    "        # State derivative: dz/dt = A_eff * z + C * u\n",
    "        dzdt = A_eff @ z_curr + C @ u_curr\n",
    "        \n",
    "        # Euler integration\n",
    "        z[t, :] = z_curr + dt * dzdt\n",
    "    \n",
    "    return z\n",
    "\n",
    "def create_complete_dcm_spec():\n",
    "    \"\"\"Create complete DCM specification ready for estimation\"\"\"\n",
    "    \n",
    "    # Extract data\n",
    "    Y = dcm_data['game_locked']['Y']\n",
    "    U = dcm_data['inputs']['U']\n",
    "    \n",
    "    # Get priors and constraints\n",
    "    priors = setup_dcm_priors()\n",
    "    constraints = setup_parameter_constraints()\n",
    "    \n",
    "    return {\n",
    "        # Data\n",
    "        'Y': Y,\n",
    "        'U': U,\n",
    "        'dt': 0.001,\n",
    "        \n",
    "        # Model structure  \n",
    "        'A': dcm_data['architecture']['A'],\n",
    "        'B': dcm_data['architecture']['B'],\n",
    "        'C': dcm_data['architecture']['C'],\n",
    "        \n",
    "        # Priors and constraints\n",
    "        'priors': priors,\n",
    "        'constraints': constraints,\n",
    "        \n",
    "        # Model properties\n",
    "        'n_regions': 2,\n",
    "        'n_inputs': 3,\n",
    "        'n_timepoints': Y.shape[0],\n",
    "        'region_names': ['Electrode_3', 'Electrode_1'],\n",
    "        'input_names': ['GameOnset', 'ChoiceType', 'Outcome'],\n",
    "        \n",
    "        # Forward model and estimation settings\n",
    "        'forward_model': dcm_forward_model,\n",
    "        'estimation': {\n",
    "            'algorithm': 'variational_bayes',\n",
    "            'max_iterations': 128,\n",
    "            'convergence_threshold': 1e-4,\n",
    "            'initialization': 'prior_mean'\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Create and save complete specification\n",
    "dcm_complete = create_complete_dcm_spec()\n",
    "dcm_data['dcm_specification'] = dcm_complete\n",
    "\n",
    "with open('dcm_ready_data_s01.pkl', 'wb') as f:\n",
    "    pickle.dump(dcm_data, f)\n",
    "\n",
    "# Count free parameters\n",
    "constraints = dcm_complete['constraints']\n",
    "n_free_params = (np.sum(constraints['A_free']) + \n",
    "                 np.sum(constraints['B_free']) + \n",
    "                 np.sum(constraints['C_free']))\n",
    "\n",
    "print(f\"DCM specification complete: {dcm_complete['n_timepoints']} timepoints, \"\n",
    "      f\"{n_free_params} free parameters, ready for estimation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "091b3c61-35ba-4d0a-9d45-145934b5bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCM estimation complete (stabilized): E3→E1=-0.006, E1→E3=-0.002, success=True, using 10004 datapoints\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy import linalg\n",
    "import pickle\n",
    "\n",
    "# Load complete DCM specification\n",
    "with open('dcm_ready_data_s01.pkl', 'rb') as f:\n",
    "    dcm_data = pickle.load(f)\n",
    "\n",
    "dcm_spec = dcm_data['dcm_specification']\n",
    "\n",
    "def unpack_parameters(theta, constraints, priors):\n",
    "    \"\"\"Convert parameter vector back to A, B, C matrices\"\"\"\n",
    "    A = priors['A']['mean'].copy()\n",
    "    B = priors['B']['mean'].copy()  \n",
    "    C = priors['C']['mean'].copy()\n",
    "    \n",
    "    # Unpack parameter vector\n",
    "    idx = 0\n",
    "    \n",
    "    # A parameters\n",
    "    n_A = np.sum(constraints['A_free'])\n",
    "    A[constraints['A_free']] = theta[idx:idx+n_A]\n",
    "    idx += n_A\n",
    "    \n",
    "    # B parameters\n",
    "    n_B = np.sum(constraints['B_free'])\n",
    "    B[constraints['B_free']] = theta[idx:idx+n_B]\n",
    "    idx += n_B\n",
    "    \n",
    "    # C parameters\n",
    "    n_C = np.sum(constraints['C_free'])\n",
    "    C[constraints['C_free']] = theta[idx:idx+n_C]\n",
    "    \n",
    "    return A, B, C\n",
    "\n",
    "def log_likelihood(theta, Y_obs, U, priors, constraints):\n",
    "    \"\"\"Compute log-likelihood of parameters given data\"\"\"\n",
    "    # Check for invalid parameters first\n",
    "    if np.any(~np.isfinite(theta)) or np.any(np.abs(theta) > 5.0):\n",
    "        return -1e10  # Return large negative value instead of -inf\n",
    "    \n",
    "    try:\n",
    "        # Unpack parameters\n",
    "        A, B, C = unpack_parameters(theta, constraints, priors)\n",
    "        \n",
    "        # Enhanced stability check\n",
    "        eigenvals = np.real(linalg.eigvals(A))\n",
    "        if np.any(eigenvals > -0.05) or np.any(~np.isfinite(eigenvals)):\n",
    "            return -1e10  # Unstable system\n",
    "        \n",
    "        # Simulate response using forward model (use smaller subset for stability)\n",
    "        n_subset = min(10000, Y_obs.shape[0])  # Reduced for stability\n",
    "        Y_pred = dcm_spec['forward_model']({'A': A, 'B': B, 'C': C}, \n",
    "                                         U[:n_subset, :])\n",
    "        \n",
    "        # Check for NaN/inf in predictions\n",
    "        if np.any(~np.isfinite(Y_pred)):\n",
    "            return -1e10\n",
    "        \n",
    "        # Compute log-likelihood with regularization\n",
    "        residuals = Y_obs[:n_subset, :] - Y_pred\n",
    "        \n",
    "        # Robust noise estimation\n",
    "        sigma2 = max(0.01, np.var(residuals) + 1e-6)  # Prevent zero variance\n",
    "        \n",
    "        # Regularized log-likelihood\n",
    "        mse = np.mean(residuals**2)\n",
    "        if not np.isfinite(mse):\n",
    "            return -1e10\n",
    "            \n",
    "        log_lik = -0.5 * mse / sigma2 * n_subset - 0.5 * n_subset * np.log(2*np.pi*sigma2)\n",
    "        \n",
    "        # Regularized priors (prevent division by zero)\n",
    "        log_prior = 0.0\n",
    "        \n",
    "        # A prior with regularization\n",
    "        A_residual = A - priors['A']['mean']\n",
    "        A_var_reg = priors['A']['variance'][constraints['A_free']] + 1e-6\n",
    "        log_prior += -0.5 * np.sum((A_residual[constraints['A_free']])**2 / A_var_reg)\n",
    "        \n",
    "        # B prior with regularization  \n",
    "        B_residual = B - priors['B']['mean']\n",
    "        B_var_reg = priors['B']['variance'][constraints['B_free']] + 1e-6\n",
    "        log_prior += -0.5 * np.sum((B_residual[constraints['B_free']])**2 / B_var_reg)\n",
    "        \n",
    "        # C prior with regularization\n",
    "        C_residual = C - priors['C']['mean']\n",
    "        C_var_reg = priors['C']['variance'][constraints['C_free']] + 1e-6\n",
    "        log_prior += -0.5 * np.sum((C_residual[constraints['C_free']])**2 / C_var_reg)\n",
    "        \n",
    "        total_log_lik = log_lik + log_prior\n",
    "        \n",
    "        # Final check for validity\n",
    "        if not np.isfinite(total_log_lik):\n",
    "            return -1e10\n",
    "            \n",
    "        return total_log_lik\n",
    "        \n",
    "    except:\n",
    "        return -1e10\n",
    "\n",
    "def estimate_dcm_parameters(Y_obs, U, priors, constraints, method='L-BFGS-B'):\n",
    "    \"\"\"Estimate DCM parameters using maximum a posteriori (MAP)\"\"\"\n",
    "    \n",
    "    # Initial parameter vector (start from prior means with small perturbation)\n",
    "    theta_init = np.concatenate([\n",
    "        priors['A']['mean'][constraints['A_free']],\n",
    "        priors['B']['mean'][constraints['B_free']],  \n",
    "        priors['C']['mean'][constraints['C_free']]\n",
    "    ])\n",
    "    \n",
    "    # Add small random perturbation to avoid local minima\n",
    "    theta_init += np.random.normal(0, 0.01, len(theta_init))\n",
    "    \n",
    "    # Define objective function (negative log-posterior)\n",
    "    def objective(theta):\n",
    "        return -log_likelihood(theta, Y_obs, U, priors, constraints)\n",
    "    \n",
    "    # Tighter parameter bounds to prevent instability\n",
    "    bounds = [(-1.5, 1.5) for _ in range(len(theta_init))]\n",
    "    \n",
    "    # More conservative optimization settings\n",
    "    result = minimize(objective, theta_init, method=method, bounds=bounds,\n",
    "                     options={\n",
    "                         'maxiter': 50,     # Reduced iterations\n",
    "                         'ftol': 1e-6,      # Function tolerance\n",
    "                         'gtol': 1e-5,      # Gradient tolerance  \n",
    "                         'disp': False,\n",
    "                         'maxfun': 1000     # Max function evaluations\n",
    "                     })\n",
    "    \n",
    "    return result, theta_init\n",
    "\n",
    "def finalize_dcm_results(result, theta_init, priors, constraints):\n",
    "    \"\"\"Extract and organize final DCM results\"\"\"\n",
    "    \n",
    "    # Get final parameters\n",
    "    theta_final = result.x if result.success else theta_init\n",
    "    A_final, B_final, C_final = unpack_parameters(theta_final, constraints, priors)\n",
    "    \n",
    "    # Create results summary\n",
    "    dcm_results = {\n",
    "        'parameters': {\n",
    "            'A': A_final,\n",
    "            'B': B_final, \n",
    "            'C': C_final,\n",
    "            'theta_vector': theta_final\n",
    "        },\n",
    "        'estimation': {\n",
    "            'success': result.success,\n",
    "            'log_likelihood': -result.fun if result.success else None,\n",
    "            'iterations': result.nit if hasattr(result, 'nit') else None,\n",
    "            'method': 'MAP estimation'\n",
    "        },\n",
    "        'connectivity_summary': {\n",
    "            'E3_to_E1': A_final[1, 0],\n",
    "            'E1_to_E3': A_final[0, 1],\n",
    "            'E3_self': A_final[0, 0],\n",
    "            'E1_self': A_final[1, 1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return dcm_results\n",
    "\n",
    "# Extract data\n",
    "Y_obs = dcm_spec['Y']\n",
    "U = dcm_spec['U']\n",
    "priors = dcm_spec['priors']\n",
    "constraints = dcm_spec['constraints']\n",
    "\n",
    "# Use conservative computational subset for stability\n",
    "subsample_factor = max(10, Y_obs.shape[0] // 10000)  # Ensure <= 10k points for stability\n",
    "Y_subset = Y_obs[::subsample_factor, :]\n",
    "U_subset = U[::subsample_factor, :]\n",
    "\n",
    "# Additional data validation\n",
    "if np.any(~np.isfinite(Y_subset)) or np.any(~np.isfinite(U_subset)):\n",
    "    print(\"Warning: Data contains NaN/inf values, attempting to clean...\")\n",
    "    Y_subset = np.nan_to_num(Y_subset, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    U_subset = np.nan_to_num(U_subset, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "\n",
    "# Run estimation\n",
    "result, theta_init = estimate_dcm_parameters(Y_subset, U_subset, priors, constraints)\n",
    "\n",
    "# Finalize results\n",
    "dcm_results = finalize_dcm_results(result, theta_init, priors, constraints)\n",
    "\n",
    "# Save results\n",
    "dcm_data['dcm_results'] = dcm_results\n",
    "\n",
    "with open('dcm_ready_data_s01.pkl', 'wb') as f:\n",
    "    pickle.dump(dcm_data, f)\n",
    "\n",
    "# Report results\n",
    "connectivity = dcm_results['connectivity_summary']\n",
    "print(f\"DCM estimation complete (stabilized): E3→E1={connectivity['E3_to_E1']:.3f}, \"\n",
    "      f\"E1→E3={connectivity['E1_to_E3']:.3f}, \"\n",
    "      f\"success={dcm_results['estimation']['success']}, \"\n",
    "      f\"using {Y_subset.shape[0]} datapoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a36935-3df5-42c1-8e44-e9fcc337a575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
